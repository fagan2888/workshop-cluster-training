{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Effective Cluster Usage and Data Management \u00b6 Wednesday, March 27, 2019. 3-4 PM. Perkins. Pre-requisites \u00b6 Please perform the following steps before the workshop , in the interest of time. You can stop by my desk at any point before the workshop if you need help with these: You should have an account on the RCE Cluster . If you do not have an account, look at Accessing the RCE for instructions on how to obtain one. You should be able to login to the cluster using the graphical client instructions here If you're using Windows, download and install PuTTY If you're on a Mac, download and install Xquartz Download and install FileZilla If you can follow the instructions here , go ahead and configure FileZilla. Download and install Atom If you already know how to, go ahead and install the following packages for Atom: remote-ftp hydrogen language-stata Download and install miniconda , if you don't already have conda. Workshop Topics \u00b6 Project folder structures and data management How to achieve sanity when your project's folders and data are a mess (i.e. restructuring your project's folders) Data management for CID Planning for a new project Folder structures Best practices and documentation Scripts for reorganizing existing folders Cluster usage Basic terminal usage How to submit jobs on the cluster and manage them Using Atom to edit files remotely Using FileZilla to upload / download files Using Python / Stata remotely Tips / tricks: How to write code that other people can run How to run Python / R / Stata code on the cluster without explicitly having to open the cluster's interface Brief intro to parallel computing","title":"Home"},{"location":"#effective-cluster-usage-and-data-management","text":"Wednesday, March 27, 2019. 3-4 PM. Perkins.","title":"Effective Cluster Usage and Data Management"},{"location":"#pre-requisites","text":"Please perform the following steps before the workshop , in the interest of time. You can stop by my desk at any point before the workshop if you need help with these: You should have an account on the RCE Cluster . If you do not have an account, look at Accessing the RCE for instructions on how to obtain one. You should be able to login to the cluster using the graphical client instructions here If you're using Windows, download and install PuTTY If you're on a Mac, download and install Xquartz Download and install FileZilla If you can follow the instructions here , go ahead and configure FileZilla. Download and install Atom If you already know how to, go ahead and install the following packages for Atom: remote-ftp hydrogen language-stata Download and install miniconda , if you don't already have conda.","title":"Pre-requisites"},{"location":"#workshop-topics","text":"Project folder structures and data management How to achieve sanity when your project's folders and data are a mess (i.e. restructuring your project's folders) Data management for CID Planning for a new project Folder structures Best practices and documentation Scripts for reorganizing existing folders Cluster usage Basic terminal usage How to submit jobs on the cluster and manage them Using Atom to edit files remotely Using FileZilla to upload / download files Using Python / Stata remotely Tips / tricks: How to write code that other people can run How to run Python / R / Stata code on the cluster without explicitly having to open the cluster's interface Brief intro to parallel computing","title":"Workshop Topics"},{"location":"cluster_usage/basic_cluster_usage/","text":"Basic cluster usage \u00b6 Working with Linux \u00b6 The RCE cluster runs on Linux. This section discusses some commands that might be useful for everday cluster usage: Change directory: cd <path to directory> Create new folder in current directory: mkdir <name of new folder> List contents of current directory: ls Including hidden files: ls -al With file sizes in KB/MB/GB instead of bytes: ls -alh Create an empty file: touch <filename> Open a Vim text editor: vi <filename> (There are a bunch of vim specific commands you need to learn to use Vim) Output the contents of a text file: cat <filename> Output the first few lines of a file: head <filename> Copy file: cp <old_file_path> <new_file_path> Move file: mv <old_file_path> <new_file_path> Rename file: mv <old_file_name> <new_file_name> Remove file: rm <file_name> For more commonly used commands, here's a cheatsheet RCE-Specific Commands \u00b6 The RCE cluster uses a framework called HTCondor. The following commands can be used for any cluster that runs on HTCondor. Connect to the RCE login node: ssh <username>@rce.hmdc.harvard.edu Connect to the RCE login node with port-forwarding: ssh -L 8889:localhost:8889 <username>@rce.hmdc.harvard.edu Check the status of your jobs: condor_q -global <username> SSH to job from the login node: condor_ssh_to_job -name \"<name of machine where job is running>\" <JobID> Check available resources: rce-info.sh Submit jobs: condor_submit <submit_file_path> or condor_submit_util Remove running jobs: condor_rm -name \"<name of the machine where job is running>\" <JobID> Other Relevant Commands \u00b6 Start new tmux session: tmux new Re-attach the last tmux session: tmux a Kill all running tmux sessions: tmux kill-server Optional Tips \u00b6 Setting up SSH Key Access \u00b6 If you don't want to type your password each time you SSH (from a computer you trust, of course), set up SSH keys. Steps (for Linux and MacOS): Check for existing SSH keys If you don't have existing keys, generate a key If you have existing keys, add to ssh-agent Upload the key to the remote server, using ssh-copy-id -i ~/.ssh/id_rsa.pub <username>@rce.hmdc.harvard.edu","title":"Basic Commands"},{"location":"cluster_usage/basic_cluster_usage/#basic-cluster-usage","text":"","title":"Basic cluster usage"},{"location":"cluster_usage/basic_cluster_usage/#working-with-linux","text":"The RCE cluster runs on Linux. This section discusses some commands that might be useful for everday cluster usage: Change directory: cd <path to directory> Create new folder in current directory: mkdir <name of new folder> List contents of current directory: ls Including hidden files: ls -al With file sizes in KB/MB/GB instead of bytes: ls -alh Create an empty file: touch <filename> Open a Vim text editor: vi <filename> (There are a bunch of vim specific commands you need to learn to use Vim) Output the contents of a text file: cat <filename> Output the first few lines of a file: head <filename> Copy file: cp <old_file_path> <new_file_path> Move file: mv <old_file_path> <new_file_path> Rename file: mv <old_file_name> <new_file_name> Remove file: rm <file_name> For more commonly used commands, here's a cheatsheet","title":"Working with Linux"},{"location":"cluster_usage/basic_cluster_usage/#rce-specific-commands","text":"The RCE cluster uses a framework called HTCondor. The following commands can be used for any cluster that runs on HTCondor. Connect to the RCE login node: ssh <username>@rce.hmdc.harvard.edu Connect to the RCE login node with port-forwarding: ssh -L 8889:localhost:8889 <username>@rce.hmdc.harvard.edu Check the status of your jobs: condor_q -global <username> SSH to job from the login node: condor_ssh_to_job -name \"<name of machine where job is running>\" <JobID> Check available resources: rce-info.sh Submit jobs: condor_submit <submit_file_path> or condor_submit_util Remove running jobs: condor_rm -name \"<name of the machine where job is running>\" <JobID>","title":"RCE-Specific Commands"},{"location":"cluster_usage/basic_cluster_usage/#other-relevant-commands","text":"Start new tmux session: tmux new Re-attach the last tmux session: tmux a Kill all running tmux sessions: tmux kill-server","title":"Other Relevant Commands"},{"location":"cluster_usage/basic_cluster_usage/#optional-tips","text":"","title":"Optional Tips"},{"location":"cluster_usage/basic_cluster_usage/#setting-up-ssh-key-access","text":"If you don't want to type your password each time you SSH (from a computer you trust, of course), set up SSH keys. Steps (for Linux and MacOS): Check for existing SSH keys If you don't have existing keys, generate a key If you have existing keys, add to ssh-agent Upload the key to the remote server, using ssh-copy-id -i ~/.ssh/id_rsa.pub <username>@rce.hmdc.harvard.edu","title":"Setting up SSH Key Access"},{"location":"cluster_usage/remote_python_options/","text":"Option 1: Jupyter Lab \u00b6 Note Compared to working with Jupyter notebooks on the cluster using the NoMachine GUI (which is stuttery because of high latency), running them remotely provides a convenient low latency alternative Although Jupyter notebooks have become the de facto method to work on Python, since they are not simple text files, they are harder to manage using Git than .py scripts Setup \u00b6 SSH into the cluster, using portforwarding 1 2 # Replace \"<rce_username>\" with your RCE username ssh -L 8889 :localhost:8889 <rce_username>@rce.hmdc.harvard.edu Load conda into the shell and set necessary environment variables Warning Be careful while editing ~/.bashrc and ~/.bash_profile files - they are executed each time your shell opens, and you don't want to mess it up and be unable to access your account. Add the following lines to your ~/.bashrc (replace <path_to_environment> and <path_to_packages> ): 1 2 3 4 5 6 7 8 # Start conda . /nfs/tools/lib/anaconda/3-5.2.0/etc/profile.d/conda.sh # Tell conda where to save and look for environments # Example: export CONDA_ENVS_PATH=\"/nfs/projects_nobackup_ci3/m/ci3_mastercard/shreyas/utils/envs/\" export CONDA_ENVS_PATH = \"<path_to_environment>\" # Tell conda where to save and look for packages # Example: export CONDA_PKGS_DIRS=\"/nfs/projects_nobackup_ci3/m/ci3_mastercard/shreyas/utils/pkgs/\" export CONDA_PKGS_DIRS = \"<path_to_packages>\" If you aren't sure how to edit your .bashrc , run the following commands and it'll do it for you (you still have to replace <path_to_environment> and <path_to_packages> ): 1 2 3 4 echo \". /nfs/tools/lib/anaconda/3-5.2.0/etc/profile.d/conda.sh\" >> ~/.bashrc # Set required environment variables to specify location of environment echo \"export CONDA_ENVS_PATH=\\\"<path_to_environment>\\\"\" >> ~/.bashrc echo \"export CONDA_PKGS_DIRS=\\\"<path_to_packages>\\\"\" >> ~/.bashrc Rerun .bashrc : 1 . ~/.bashrc Create and prepare a conda environment, and activate it with the following commands: 1 2 3 4 5 6 7 8 9 10 11 # Navigate to <path_to_environment> cd <path_to_environment> # Create conda environment in the current folder conda create --prefix = cid python = 3 # Activate conda environment (can now be done from any folder) conda activate cid # Install necessary packages ## Add conda-forge as the main channel for downloading packages (optional) conda config --add channels conda-forge ## Download required packages conda install -c conda-forge jupyterlab nodejs Prepare condor submission and connection scripts (replace <your_token> ) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # Make a directory somewhere to house the condor scripts mkdir -p ~/condorscripts/condorlogs && cd ~/condorscripts # Download Jupyter submission script from Github Repo curl -O https://raw.githubusercontent.com/cid-harvard/workshop-cluster-training/master/assets/condorscripts/jupyter.submit # Automatically replace \"~\" in jupyter.submit with the absolute path to your HOME directory sed -i 's@\\~@' \" $HOME \" '@' jupyter.submit # Download Jupyter connection script curl -O https://raw.githubusercontent.com/cid-harvard/workshop-cluster-training/master/assets/condorscripts/condorsshrce.sh # Automatically replace \"username\" with the username sed -i 's/username/' \" $USER \" '/' condorsshrce.sh # Download shell script to activate conda env named 'cid' and run Jupyter curl -O https://raw.githubusercontent.com/cid-harvard/workshop-cluster-training/master/assets/condorscripts/run_jupyter.sh # Replace \"<your_token>\" with token of your choice # Example: sed -i 's/my_token/example_token/' run_jupyter.sh sed -i 's/my_token/<your_token>/' run_jupyter.sh Running Python through Jupyter \u00b6 SSH into the cluster, using portforwarding (if you haven't yet) 1 2 # Replace \"<rce_username>\" with your RCE username ssh -L 8889 :localhost:8889 <rce_username>@rce.hmdc.harvard.edu Submit Jupyter job 1 2 # Submit condor script condor_submit ~/condorscripts/jupyter.submit Use tmux to handle connection errors/closures (optional) 1 2 # Start a new tmux window tmux new Connect to the Jupyter server 1 2 # SSH to the machine running your jupyter server . ~/condorscripts/condorsshrce.sh $USER Tip: tmux keyboard shortcuts and commands New tmux window: tmux new Detach tmux window: ctrl+b , then d Reattach latest tmux window: tmux a New horizontal pane: ctrl+b , then \" New vertical pane: ctrl+b , then % Kill current pane: ctrl+b , then x , then y Move between panes: ctrl+b , then arrow keys Stop moving, or cancel a tmux-specific command: escape Kill all tmux sessions: tmux kill-server In your browser, go to localhost:8889 , and voila! Once you're done, you can close the compute node using ctrl+d , you might then have to press ctrl+c if your login node is taking time to appear Remember to remove the job once you're finished: 1 2 3 4 # Look up running jobs condor_q -global $USER # Remove job condor_rm -name \"<machine_name>\" <ID> Example Option 2: Atom + Hydrogen \u00b6 Note The text editor Atom, using the package Hydrogen, allows you to run code interactively, inspect data and plot using Jupyter kernels. Allows the option of working on .py files directly, with low latency. Setup \u00b6 Setting up the Jupyter Kernel \u00b6 The steps for setting up the Jupyter kernel are the same as for Option 1: Jupyter Lab . Setting up Atom \u00b6 You can learn some Atom basics here Install required packages To install a package on atom, press Cmd+Shift+P (Mac) or Cmd+Shift+P (Windows) to enter the \"Command Palette\", and type Install Packages . Install the following packages: remote-ftp : enable browsing remote files hydrogen : run code through jupyter kernels Optional (my favourite add-ons): tree-view : explore files in project file-icons : convenient file icons in tree view atom-beautify : automatically indent / beautify code according to linters open-recent : open recently opened files / projects teletype : collaborate on code in real-time (think google docs for code) highlight-selected : highlight all occurrences of selected word or phrase minimap : mini view of the code on the side Configure remote_ftp Create an empty folder in your computer. Call it remote_atom (or any other name you might see fit). Open Atom and click \"File -> Open -> remote_atom \". This will open the remote_atom folder as a \"project\". Open the Command Palette ( Cmd+Shift+P or Ctrl+Shift+P ) and type \"Create Sftp\" and choose the option \"Remote Ftp: Create Sftp Config File\". You will notice that a file named .ftpconfig is automatically created in the same folder. Replace the contents of the file with the following, modifying the user and remote parameters: 1 2 3 4 5 6 7 8 9 10 { \"protocol\" : \"sftp\" , \"host\" : \"rce.hmdc.harvard.edu\" , // string - Hostname or IP address of the server. Default: 'localhost' \"port\" : 22 , // integer - Port number of the server. Default: 22 \"user\" : \"<username>\" , // string - Username for authentication. Default: (none) \"promptForPass\" : true , // boolean - Set to true for enable password/passphrase dialog. This will prevent from using cleartext password/passphrase in this config. Default: false \"remote\" : \"/nfs/home/S/shg309/ <replace with your own home folder>\" , // try to use absolute paths starting with / \"connTimeout\" : 10000 , // integer - How long (in milliseconds) to wait for the SSH handshake to complete. Default: 10000 \"keepalive\" : 10000 // integer - How often (in milliseconds) to send SSH-level keepalive packets to the server (in a similar way as OpenSSH's ServerAliveInterval config option). Set to 0 to disable. Default : 10000 } Open the Command Palette and type \"Remote Ftp\", and choose the option Toggle . This will open up a Remote tab on the left hand side. In the Remote tab, click on Connect , and voila! You can now edit files on the cluster as if they were on your own computer! Warning Don't use the remote_atom project unless you're working on the cluster. The files in the folder are uploaded automatically to the cluster when you reconnect. Note Once you're done, remember to Disconnect . Optional: Through the Command Palette, go to \"View Installed Packages\" --> remote_ftp's settings --> change Auto Upload on Save from always to only when connected Configure Hydrogen Through the Command Palette, go to \"View Installed Packages\" --> hydrogen's settings --> change Kernel Gateways to the following (replace <your_token> with the token you set for Jupyter earlier): 1 [{ \"name\" : \"RCE Jupyter\" , \"options\" :{ \"baseUrl\" : \"http://localhost:8889\" , \"token\" : \"<your_token>\" }}] Running Python through Hydrogen \u00b6 Connect to Remote Kernel Open a Python .py script Through the Command Palette, go to \"Connect to Remote Kernel\". Troubleshooting If you haven't set a token, you might be asked to \"Authenticate Using Token\". To find the authentication token, on an RCE node, type the following: 1 2 3 4 # Activate conda environment conda activate cid # Get Jupyter token jupyter notebook list The token will be of the form: http://localhost:8889/?token= a61elkjziunns1523e70eb18a452cfsdf9812302199b87e Running code Select code you want to run, and hit Cmd+Enter (Mac) or Ctrl+Enter (Windows) To run all code, hit Cmd+Option+Enter (Mac) or Ctrl+Alt+Enter (Windows) Magics You can use Jupyter magics through Hydrogen 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 % reset - f # Reset all variables in memory % matplotlib inline # Inline matplotlib figures import numpy as np import pandas as pd import matplotlib.pyplot as plt # Simple tests print ( 'Hello world!' ) 17 + 25 # Print dataframe pd . DataFrame ({ 'col1' : [ 1 , 2 ], 'col2' : [ 3 , 4 ]}) # Show plot N = 50 x = np . random . rand ( N ) y = np . random . rand ( N ) colors = np . random . rand ( N ) area = ( 30 * np . random . rand ( N )) ** 2 # 0 to 15 point radii plt . scatter ( x , y , s = area , c = colors , alpha = 0.5 ) plt . show ()","title":"Running Python Remotely"},{"location":"cluster_usage/remote_python_options/#option-1-jupyter-lab","text":"Note Compared to working with Jupyter notebooks on the cluster using the NoMachine GUI (which is stuttery because of high latency), running them remotely provides a convenient low latency alternative Although Jupyter notebooks have become the de facto method to work on Python, since they are not simple text files, they are harder to manage using Git than .py scripts","title":"Option 1: Jupyter Lab"},{"location":"cluster_usage/remote_python_options/#setup","text":"SSH into the cluster, using portforwarding 1 2 # Replace \"<rce_username>\" with your RCE username ssh -L 8889 :localhost:8889 <rce_username>@rce.hmdc.harvard.edu Load conda into the shell and set necessary environment variables Warning Be careful while editing ~/.bashrc and ~/.bash_profile files - they are executed each time your shell opens, and you don't want to mess it up and be unable to access your account. Add the following lines to your ~/.bashrc (replace <path_to_environment> and <path_to_packages> ): 1 2 3 4 5 6 7 8 # Start conda . /nfs/tools/lib/anaconda/3-5.2.0/etc/profile.d/conda.sh # Tell conda where to save and look for environments # Example: export CONDA_ENVS_PATH=\"/nfs/projects_nobackup_ci3/m/ci3_mastercard/shreyas/utils/envs/\" export CONDA_ENVS_PATH = \"<path_to_environment>\" # Tell conda where to save and look for packages # Example: export CONDA_PKGS_DIRS=\"/nfs/projects_nobackup_ci3/m/ci3_mastercard/shreyas/utils/pkgs/\" export CONDA_PKGS_DIRS = \"<path_to_packages>\" If you aren't sure how to edit your .bashrc , run the following commands and it'll do it for you (you still have to replace <path_to_environment> and <path_to_packages> ): 1 2 3 4 echo \". /nfs/tools/lib/anaconda/3-5.2.0/etc/profile.d/conda.sh\" >> ~/.bashrc # Set required environment variables to specify location of environment echo \"export CONDA_ENVS_PATH=\\\"<path_to_environment>\\\"\" >> ~/.bashrc echo \"export CONDA_PKGS_DIRS=\\\"<path_to_packages>\\\"\" >> ~/.bashrc Rerun .bashrc : 1 . ~/.bashrc Create and prepare a conda environment, and activate it with the following commands: 1 2 3 4 5 6 7 8 9 10 11 # Navigate to <path_to_environment> cd <path_to_environment> # Create conda environment in the current folder conda create --prefix = cid python = 3 # Activate conda environment (can now be done from any folder) conda activate cid # Install necessary packages ## Add conda-forge as the main channel for downloading packages (optional) conda config --add channels conda-forge ## Download required packages conda install -c conda-forge jupyterlab nodejs Prepare condor submission and connection scripts (replace <your_token> ) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # Make a directory somewhere to house the condor scripts mkdir -p ~/condorscripts/condorlogs && cd ~/condorscripts # Download Jupyter submission script from Github Repo curl -O https://raw.githubusercontent.com/cid-harvard/workshop-cluster-training/master/assets/condorscripts/jupyter.submit # Automatically replace \"~\" in jupyter.submit with the absolute path to your HOME directory sed -i 's@\\~@' \" $HOME \" '@' jupyter.submit # Download Jupyter connection script curl -O https://raw.githubusercontent.com/cid-harvard/workshop-cluster-training/master/assets/condorscripts/condorsshrce.sh # Automatically replace \"username\" with the username sed -i 's/username/' \" $USER \" '/' condorsshrce.sh # Download shell script to activate conda env named 'cid' and run Jupyter curl -O https://raw.githubusercontent.com/cid-harvard/workshop-cluster-training/master/assets/condorscripts/run_jupyter.sh # Replace \"<your_token>\" with token of your choice # Example: sed -i 's/my_token/example_token/' run_jupyter.sh sed -i 's/my_token/<your_token>/' run_jupyter.sh","title":"Setup"},{"location":"cluster_usage/remote_python_options/#running-python-through-jupyter","text":"SSH into the cluster, using portforwarding (if you haven't yet) 1 2 # Replace \"<rce_username>\" with your RCE username ssh -L 8889 :localhost:8889 <rce_username>@rce.hmdc.harvard.edu Submit Jupyter job 1 2 # Submit condor script condor_submit ~/condorscripts/jupyter.submit Use tmux to handle connection errors/closures (optional) 1 2 # Start a new tmux window tmux new Connect to the Jupyter server 1 2 # SSH to the machine running your jupyter server . ~/condorscripts/condorsshrce.sh $USER Tip: tmux keyboard shortcuts and commands New tmux window: tmux new Detach tmux window: ctrl+b , then d Reattach latest tmux window: tmux a New horizontal pane: ctrl+b , then \" New vertical pane: ctrl+b , then % Kill current pane: ctrl+b , then x , then y Move between panes: ctrl+b , then arrow keys Stop moving, or cancel a tmux-specific command: escape Kill all tmux sessions: tmux kill-server In your browser, go to localhost:8889 , and voila! Once you're done, you can close the compute node using ctrl+d , you might then have to press ctrl+c if your login node is taking time to appear Remember to remove the job once you're finished: 1 2 3 4 # Look up running jobs condor_q -global $USER # Remove job condor_rm -name \"<machine_name>\" <ID> Example","title":"Running Python through Jupyter"},{"location":"cluster_usage/remote_python_options/#option-2-atom-hydrogen","text":"Note The text editor Atom, using the package Hydrogen, allows you to run code interactively, inspect data and plot using Jupyter kernels. Allows the option of working on .py files directly, with low latency.","title":"Option 2: Atom + Hydrogen"},{"location":"cluster_usage/remote_python_options/#setup_1","text":"","title":"Setup"},{"location":"cluster_usage/remote_python_options/#setting-up-the-jupyter-kernel","text":"The steps for setting up the Jupyter kernel are the same as for Option 1: Jupyter Lab .","title":"Setting up the Jupyter Kernel"},{"location":"cluster_usage/remote_python_options/#setting-up-atom","text":"You can learn some Atom basics here Install required packages To install a package on atom, press Cmd+Shift+P (Mac) or Cmd+Shift+P (Windows) to enter the \"Command Palette\", and type Install Packages . Install the following packages: remote-ftp : enable browsing remote files hydrogen : run code through jupyter kernels Optional (my favourite add-ons): tree-view : explore files in project file-icons : convenient file icons in tree view atom-beautify : automatically indent / beautify code according to linters open-recent : open recently opened files / projects teletype : collaborate on code in real-time (think google docs for code) highlight-selected : highlight all occurrences of selected word or phrase minimap : mini view of the code on the side Configure remote_ftp Create an empty folder in your computer. Call it remote_atom (or any other name you might see fit). Open Atom and click \"File -> Open -> remote_atom \". This will open the remote_atom folder as a \"project\". Open the Command Palette ( Cmd+Shift+P or Ctrl+Shift+P ) and type \"Create Sftp\" and choose the option \"Remote Ftp: Create Sftp Config File\". You will notice that a file named .ftpconfig is automatically created in the same folder. Replace the contents of the file with the following, modifying the user and remote parameters: 1 2 3 4 5 6 7 8 9 10 { \"protocol\" : \"sftp\" , \"host\" : \"rce.hmdc.harvard.edu\" , // string - Hostname or IP address of the server. Default: 'localhost' \"port\" : 22 , // integer - Port number of the server. Default: 22 \"user\" : \"<username>\" , // string - Username for authentication. Default: (none) \"promptForPass\" : true , // boolean - Set to true for enable password/passphrase dialog. This will prevent from using cleartext password/passphrase in this config. Default: false \"remote\" : \"/nfs/home/S/shg309/ <replace with your own home folder>\" , // try to use absolute paths starting with / \"connTimeout\" : 10000 , // integer - How long (in milliseconds) to wait for the SSH handshake to complete. Default: 10000 \"keepalive\" : 10000 // integer - How often (in milliseconds) to send SSH-level keepalive packets to the server (in a similar way as OpenSSH's ServerAliveInterval config option). Set to 0 to disable. Default : 10000 } Open the Command Palette and type \"Remote Ftp\", and choose the option Toggle . This will open up a Remote tab on the left hand side. In the Remote tab, click on Connect , and voila! You can now edit files on the cluster as if they were on your own computer! Warning Don't use the remote_atom project unless you're working on the cluster. The files in the folder are uploaded automatically to the cluster when you reconnect. Note Once you're done, remember to Disconnect . Optional: Through the Command Palette, go to \"View Installed Packages\" --> remote_ftp's settings --> change Auto Upload on Save from always to only when connected Configure Hydrogen Through the Command Palette, go to \"View Installed Packages\" --> hydrogen's settings --> change Kernel Gateways to the following (replace <your_token> with the token you set for Jupyter earlier): 1 [{ \"name\" : \"RCE Jupyter\" , \"options\" :{ \"baseUrl\" : \"http://localhost:8889\" , \"token\" : \"<your_token>\" }}]","title":"Setting up Atom"},{"location":"cluster_usage/remote_python_options/#running-python-through-hydrogen","text":"Connect to Remote Kernel Open a Python .py script Through the Command Palette, go to \"Connect to Remote Kernel\". Troubleshooting If you haven't set a token, you might be asked to \"Authenticate Using Token\". To find the authentication token, on an RCE node, type the following: 1 2 3 4 # Activate conda environment conda activate cid # Get Jupyter token jupyter notebook list The token will be of the form: http://localhost:8889/?token= a61elkjziunns1523e70eb18a452cfsdf9812302199b87e Running code Select code you want to run, and hit Cmd+Enter (Mac) or Ctrl+Enter (Windows) To run all code, hit Cmd+Option+Enter (Mac) or Ctrl+Alt+Enter (Windows) Magics You can use Jupyter magics through Hydrogen 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 % reset - f # Reset all variables in memory % matplotlib inline # Inline matplotlib figures import numpy as np import pandas as pd import matplotlib.pyplot as plt # Simple tests print ( 'Hello world!' ) 17 + 25 # Print dataframe pd . DataFrame ({ 'col1' : [ 1 , 2 ], 'col2' : [ 3 , 4 ]}) # Show plot N = 50 x = np . random . rand ( N ) y = np . random . rand ( N ) colors = np . random . rand ( N ) area = ( 30 * np . random . rand ( N )) ** 2 # 0 to 15 point radii plt . scatter ( x , y , s = area , c = colors , alpha = 0.5 ) plt . show ()","title":"Running Python through Hydrogen"},{"location":"cluster_usage/remote_stata_options/","text":"Option 1: X-forwarding \u00b6 Note Gives you the actual window running Stata, but suffers from latency issues, which means that the screen will be stuttery Setup \u00b6 MacOS: Install Xquartz Edit ~/.ssh/config and add: 1 2 3 4 Host * XAuthLocation /opt/X11/bin/xauth ForwardX11 yes ForwardX11Trusted yes Windows: In PuTTy, enable X11 forwarding Linux: No setup required! X11 is pre-installed You might have to edit ~/.ssh/config to allow X11 forwarding (same as MacOS) Running Stata \u00b6 ssh to the RCE, adding a -Y flag to the command. You can use -X (untrusted X11 forwarding) or -Y (trusted X11 forwarding, slightly smoother) -Y is less secure, so only use it for applications you recognize (such as Stata) 1 2 # Replace \"<rce_username>\" with your RCE username ssh -Y <rce_username>@rce.hmdc.harvard.edu Run the RCE provided convenience-command to start STATA jobs, with a graphical interface: 1 rce_submit.py -r -graphical -a xstata-mp For commonly used commands and introductory tutorials, refer to RCE documentation . Option 2: Jupyter Lab \u00b6 Note Thanks to Kyle Barron's package stata_kernel , we can use Stata kernels for Jupyter, allowing us to run Stata remotely with low latency. However, Jupyter notebooks are not text files, so working with them does not have the do-file editor feel that Stata users might be used to. Additionally, Jupyter notebooks are harder to manage using Git Setup \u00b6 SSH into the cluster, using portforwarding 1 2 # Replace \"<rce_username>\" with your RCE username ssh -L 8889 :localhost:8889 <rce_username>@rce.hmdc.harvard.edu Load conda into the shell and set necessary environment variables Warning Be careful while editing ~/.bashrc and ~/.bash_profile files - they are executed each time your shell opens, and you don't want to mess it up and be unable to access your account. Add the following lines to your ~/.bashrc (replace <path_to_environment> and <path_to_packages> ): 1 2 3 4 5 6 7 8 # Start conda . /nfs/tools/lib/anaconda/3-5.2.0/etc/profile.d/conda.sh # Tell conda where to save and look for environments # Example: export CONDA_ENVS_PATH=\"/nfs/projects_nobackup_ci3/m/ci3_mastercard/shreyas/utils/envs/\" export CONDA_ENVS_PATH = \"<path_to_environment>\" # Tell conda where to save and look for packages # Example: export CONDA_PKGS_DIRS=\"/nfs/projects_nobackup_ci3/m/ci3_mastercard/shreyas/utils/pkgs/\" export CONDA_PKGS_DIRS = \"<path_to_packages>\" If you aren't sure how to edit your .bashrc , run the following commands and it'll do it for you (you still have to replace <path_to_environment> and <path_to_packages> ): 1 2 3 4 echo \". /nfs/tools/lib/anaconda/3-5.2.0/etc/profile.d/conda.sh\" >> ~/.bashrc # Set required environment variables to specify location of environment echo \"export CONDA_ENVS_PATH=\\\"<path_to_environment>\\\"\" >> ~/.bashrc echo \"export CONDA_PKGS_DIRS=\\\"<path_to_packages>\\\"\" >> ~/.bashrc Rerun .bashrc : 1 . ~/.bashrc Create and prepare a conda environment, and activate it with the following commands: 1 2 3 4 5 6 7 8 9 10 11 # Navigate to <path_to_environment> cd <path_to_environment> # Create conda environment in the current folder conda create --prefix = cid python = 3 # Activate conda environment (can now be done from any folder) conda activate cid # Install necessary packages ## Add conda-forge as the main channel for downloading packages (optional) conda config --add channels conda-forge ## Download required packages conda install -c conda-forge jupyterlab nodejs Install STATA for Jupyter 1 2 3 4 5 ## Install stata_kernel pip install stata_kernel python -m stata_kernel.install ## Install JupyterLab Extension for Stata syntax highlighting jupyter labextension install jupyterlab-stata-highlight Prepare condor submission and connection scripts (replace <your_token> ) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # Make a directory somewhere to house the condor scripts mkdir -p ~/condorscripts/condorlogs && cd ~/condorscripts # Download Jupyter submission script from Github Repo curl -O https://raw.githubusercontent.com/cid-harvard/workshop-cluster-training/master/assets/condorscripts/jupyter.submit # Automatically replace \"~\" in jupyter.submit with the absolute path to your HOME directory sed -i 's@\\~@' \" $HOME \" '@' jupyter.submit # Download Jupyter connection script curl -O https://raw.githubusercontent.com/cid-harvard/workshop-cluster-training/master/assets/condorscripts/condorsshrce.sh # Automatically replace \"username\" with the username sed -i 's/username/' \" $USER \" '/' condorsshrce.sh # Download shell script to activate conda env named 'cid' and run Jupyter curl -O https://raw.githubusercontent.com/cid-harvard/workshop-cluster-training/master/assets/condorscripts/run_jupyter.sh # Replace \"<your_token>\" with token of your choice # Example: sed -i 's/my_token/example_token/' run_jupyter.sh sed -i 's/my_token/<your_token>/' run_jupyter.sh Running Stata through Jupyter \u00b6 SSH into the cluster, using portforwarding (if you haven't yet) 1 2 # Replace \"<rce_username>\" with your RCE username ssh -L 8889 :localhost:8889 <rce_username>@rce.hmdc.harvard.edu Submit Jupyter job 1 2 # Submit condor script condor_submit ~/condorscripts/jupyter.submit Use tmux to handle connection errors/closures (optional) 1 2 # Start a new tmux window tmux new Connect to the Jupyter server 1 2 # SSH to the machine running your jupyter server . ~/condorscripts/condorsshrce.sh $USER Tip: tmux keyboard shortcuts and commands New tmux window: tmux new Detach tmux window: ctrl+b , then d Reattach latest tmux window: tmux a New horizontal pane: ctrl+b , then \" New vertical pane: ctrl+b , then % Kill current pane: ctrl+b , then x , then y Move between panes: ctrl+b , then arrow keys Stop moving, or cancel a tmux-specific command: escape Kill all tmux sessions: tmux kill-server In your browser, go to localhost:8889 , and voila! Once you're done, you can close the compute node using ctrl+d , you might then have to press ctrl+c if your login node is taking time to appear Remember to remove the job once you're finished: 1 2 3 4 # Look up running jobs condor_q -global $USER # Remove job condor_rm -name \"<machine_name>\" <ID> Example Option 3: Atom + Hydrogen \u00b6 Note The text editor Atom, using the package Hydrogen, allows you to run code interactively, inspect data and plot using Jupyter kernels. This method uses stata_kernel as well. Recommended option! Provides a do-file like feel , with low latency (i.e. no stuttering). Setup \u00b6 Setting up the Jupyter Kernel \u00b6 The steps for setting up the Jupyter kernel are the same as for Option 2: Jupyter Lab . Setting up Atom \u00b6 You can learn some Atom basics here Install required packages To install a package on atom, press Cmd+Shift+P (Mac) or Cmd+Shift+P (Windows) to enter the \"Command Palette\", and type Install Packages . Install the following packages: remote-ftp : enable browsing remote files hydrogen : run code through jupyter kernels language-stata : stata code linting Optional (my favourite add-ons): tree-view : explore files in project file-icons : convenient file icons in tree view atom-beautify : automatically indent / beautify code according to linters open-recent : open recently opened files / projects teletype : collaborate on code in real-time (think google docs for code) highlight-selected : highlight all occurrences of selected word or phrase minimap : mini view of the code on the side Configure remote_ftp Create an empty folder in your computer. Call it remote_atom (or any other name you might see fit). Open Atom and click \"File -> Open -> remote_atom \". This will open the remote_atom folder as a \"project\". Open the Command Palette ( Cmd+Shift+P or Ctrl+Shift+P ) and type \"Create Sftp\" and choose the option \"Remote Ftp: Create Sftp Config File\". You will notice that a file named .ftpconfig is automatically created in the same folder. Replace the contents of the file with the following, modifying the user and remote parameters: 1 2 3 4 5 6 7 8 9 10 { \"protocol\" : \"sftp\" , \"host\" : \"rce.hmdc.harvard.edu\" , // string - Hostname or IP address of the server. Default: 'localhost' \"port\" : 22 , // integer - Port number of the server. Default: 22 \"user\" : \"<username>\" , // string - Username for authentication. Default: (none) \"promptForPass\" : true , // boolean - Set to true for enable password/passphrase dialog. This will prevent from using cleartext password/passphrase in this config. Default: false \"remote\" : \"/nfs/home/S/shg309/ <replace with your own home folder>\" , // try to use absolute paths starting with / \"connTimeout\" : 10000 , // integer - How long (in milliseconds) to wait for the SSH handshake to complete. Default: 10000 \"keepalive\" : 10000 // integer - How often (in milliseconds) to send SSH-level keepalive packets to the server (in a similar way as OpenSSH's ServerAliveInterval config option). Set to 0 to disable. Default : 10000 } Open the Command Palette and type \"Remote Ftp\", and choose the option Toggle . This will open up a Remote tab on the left hand side. In the Remote tab, click on Connect , and voila! You can now edit files on the cluster as if they were on your own computer! Warning Don't use the remote_atom project unless you're working on the cluster. The files in the folder are uploaded automatically to the cluster when you reconnect. Note Once you're done, remember to Disconnect . Optional: Through the Command Palette, go to \"View Installed Packages\" --> remote_ftp's settings --> change Auto Upload on Save from always to only when connected Configure Hydrogen Through the Command Palette, go to \"View Installed Packages\" --> hydrogen's settings --> change Kernel Gateways to the following (replace <your_token> with the token you set for Jupyter earlier): 1 [{ \"name\" : \"RCE Jupyter\" , \"options\" :{ \"baseUrl\" : \"http://localhost:8889\" , \"token\" : \"<your_token>\" }}] Running Stata through Hydrogen \u00b6 Connect to Remote Kernel Open a Stata .do file Through the Command Palette, go to \"Connect to Remote Kernel\". Troubleshooting If you haven't set a token, you might be asked to \"Authenticate Using Token\". To find the authentication token, on an RCE node, type the following: 1 2 3 4 # Activate conda environment conda activate cid # Get Jupyter token jupyter notebook list The token will be of the form: http://localhost:8889/?token= a61elkjziunns1523e70eb18a452cfsdf9812302199b87e Running code Select code you want to run, and hit Cmd+Enter (Mac) or Ctrl+Enter (Windows) To run all code, hit Cmd+Option+Enter (Mac) or Ctrl+Alt+Enter (Windows) Magics For browsing data, you can use the %browse magic: 1 2 3 webuse auto scatter mpg weight %browse 100 mpg Refer to this page for more Jupyter+Stata magics.","title":"Running Stata Remotely"},{"location":"cluster_usage/remote_stata_options/#option-1-x-forwarding","text":"Note Gives you the actual window running Stata, but suffers from latency issues, which means that the screen will be stuttery","title":"Option 1: X-forwarding"},{"location":"cluster_usage/remote_stata_options/#setup","text":"MacOS: Install Xquartz Edit ~/.ssh/config and add: 1 2 3 4 Host * XAuthLocation /opt/X11/bin/xauth ForwardX11 yes ForwardX11Trusted yes Windows: In PuTTy, enable X11 forwarding Linux: No setup required! X11 is pre-installed You might have to edit ~/.ssh/config to allow X11 forwarding (same as MacOS)","title":"Setup"},{"location":"cluster_usage/remote_stata_options/#running-stata","text":"ssh to the RCE, adding a -Y flag to the command. You can use -X (untrusted X11 forwarding) or -Y (trusted X11 forwarding, slightly smoother) -Y is less secure, so only use it for applications you recognize (such as Stata) 1 2 # Replace \"<rce_username>\" with your RCE username ssh -Y <rce_username>@rce.hmdc.harvard.edu Run the RCE provided convenience-command to start STATA jobs, with a graphical interface: 1 rce_submit.py -r -graphical -a xstata-mp For commonly used commands and introductory tutorials, refer to RCE documentation .","title":"Running Stata"},{"location":"cluster_usage/remote_stata_options/#option-2-jupyter-lab","text":"Note Thanks to Kyle Barron's package stata_kernel , we can use Stata kernels for Jupyter, allowing us to run Stata remotely with low latency. However, Jupyter notebooks are not text files, so working with them does not have the do-file editor feel that Stata users might be used to. Additionally, Jupyter notebooks are harder to manage using Git","title":"Option 2: Jupyter Lab"},{"location":"cluster_usage/remote_stata_options/#setup_1","text":"SSH into the cluster, using portforwarding 1 2 # Replace \"<rce_username>\" with your RCE username ssh -L 8889 :localhost:8889 <rce_username>@rce.hmdc.harvard.edu Load conda into the shell and set necessary environment variables Warning Be careful while editing ~/.bashrc and ~/.bash_profile files - they are executed each time your shell opens, and you don't want to mess it up and be unable to access your account. Add the following lines to your ~/.bashrc (replace <path_to_environment> and <path_to_packages> ): 1 2 3 4 5 6 7 8 # Start conda . /nfs/tools/lib/anaconda/3-5.2.0/etc/profile.d/conda.sh # Tell conda where to save and look for environments # Example: export CONDA_ENVS_PATH=\"/nfs/projects_nobackup_ci3/m/ci3_mastercard/shreyas/utils/envs/\" export CONDA_ENVS_PATH = \"<path_to_environment>\" # Tell conda where to save and look for packages # Example: export CONDA_PKGS_DIRS=\"/nfs/projects_nobackup_ci3/m/ci3_mastercard/shreyas/utils/pkgs/\" export CONDA_PKGS_DIRS = \"<path_to_packages>\" If you aren't sure how to edit your .bashrc , run the following commands and it'll do it for you (you still have to replace <path_to_environment> and <path_to_packages> ): 1 2 3 4 echo \". /nfs/tools/lib/anaconda/3-5.2.0/etc/profile.d/conda.sh\" >> ~/.bashrc # Set required environment variables to specify location of environment echo \"export CONDA_ENVS_PATH=\\\"<path_to_environment>\\\"\" >> ~/.bashrc echo \"export CONDA_PKGS_DIRS=\\\"<path_to_packages>\\\"\" >> ~/.bashrc Rerun .bashrc : 1 . ~/.bashrc Create and prepare a conda environment, and activate it with the following commands: 1 2 3 4 5 6 7 8 9 10 11 # Navigate to <path_to_environment> cd <path_to_environment> # Create conda environment in the current folder conda create --prefix = cid python = 3 # Activate conda environment (can now be done from any folder) conda activate cid # Install necessary packages ## Add conda-forge as the main channel for downloading packages (optional) conda config --add channels conda-forge ## Download required packages conda install -c conda-forge jupyterlab nodejs Install STATA for Jupyter 1 2 3 4 5 ## Install stata_kernel pip install stata_kernel python -m stata_kernel.install ## Install JupyterLab Extension for Stata syntax highlighting jupyter labextension install jupyterlab-stata-highlight Prepare condor submission and connection scripts (replace <your_token> ) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # Make a directory somewhere to house the condor scripts mkdir -p ~/condorscripts/condorlogs && cd ~/condorscripts # Download Jupyter submission script from Github Repo curl -O https://raw.githubusercontent.com/cid-harvard/workshop-cluster-training/master/assets/condorscripts/jupyter.submit # Automatically replace \"~\" in jupyter.submit with the absolute path to your HOME directory sed -i 's@\\~@' \" $HOME \" '@' jupyter.submit # Download Jupyter connection script curl -O https://raw.githubusercontent.com/cid-harvard/workshop-cluster-training/master/assets/condorscripts/condorsshrce.sh # Automatically replace \"username\" with the username sed -i 's/username/' \" $USER \" '/' condorsshrce.sh # Download shell script to activate conda env named 'cid' and run Jupyter curl -O https://raw.githubusercontent.com/cid-harvard/workshop-cluster-training/master/assets/condorscripts/run_jupyter.sh # Replace \"<your_token>\" with token of your choice # Example: sed -i 's/my_token/example_token/' run_jupyter.sh sed -i 's/my_token/<your_token>/' run_jupyter.sh","title":"Setup"},{"location":"cluster_usage/remote_stata_options/#running-stata-through-jupyter","text":"SSH into the cluster, using portforwarding (if you haven't yet) 1 2 # Replace \"<rce_username>\" with your RCE username ssh -L 8889 :localhost:8889 <rce_username>@rce.hmdc.harvard.edu Submit Jupyter job 1 2 # Submit condor script condor_submit ~/condorscripts/jupyter.submit Use tmux to handle connection errors/closures (optional) 1 2 # Start a new tmux window tmux new Connect to the Jupyter server 1 2 # SSH to the machine running your jupyter server . ~/condorscripts/condorsshrce.sh $USER Tip: tmux keyboard shortcuts and commands New tmux window: tmux new Detach tmux window: ctrl+b , then d Reattach latest tmux window: tmux a New horizontal pane: ctrl+b , then \" New vertical pane: ctrl+b , then % Kill current pane: ctrl+b , then x , then y Move between panes: ctrl+b , then arrow keys Stop moving, or cancel a tmux-specific command: escape Kill all tmux sessions: tmux kill-server In your browser, go to localhost:8889 , and voila! Once you're done, you can close the compute node using ctrl+d , you might then have to press ctrl+c if your login node is taking time to appear Remember to remove the job once you're finished: 1 2 3 4 # Look up running jobs condor_q -global $USER # Remove job condor_rm -name \"<machine_name>\" <ID> Example","title":"Running Stata through Jupyter"},{"location":"cluster_usage/remote_stata_options/#option-3-atom-hydrogen","text":"Note The text editor Atom, using the package Hydrogen, allows you to run code interactively, inspect data and plot using Jupyter kernels. This method uses stata_kernel as well. Recommended option! Provides a do-file like feel , with low latency (i.e. no stuttering).","title":"Option 3: Atom + Hydrogen"},{"location":"cluster_usage/remote_stata_options/#setup_2","text":"","title":"Setup"},{"location":"cluster_usage/remote_stata_options/#setting-up-the-jupyter-kernel","text":"The steps for setting up the Jupyter kernel are the same as for Option 2: Jupyter Lab .","title":"Setting up the Jupyter Kernel"},{"location":"cluster_usage/remote_stata_options/#setting-up-atom","text":"You can learn some Atom basics here Install required packages To install a package on atom, press Cmd+Shift+P (Mac) or Cmd+Shift+P (Windows) to enter the \"Command Palette\", and type Install Packages . Install the following packages: remote-ftp : enable browsing remote files hydrogen : run code through jupyter kernels language-stata : stata code linting Optional (my favourite add-ons): tree-view : explore files in project file-icons : convenient file icons in tree view atom-beautify : automatically indent / beautify code according to linters open-recent : open recently opened files / projects teletype : collaborate on code in real-time (think google docs for code) highlight-selected : highlight all occurrences of selected word or phrase minimap : mini view of the code on the side Configure remote_ftp Create an empty folder in your computer. Call it remote_atom (or any other name you might see fit). Open Atom and click \"File -> Open -> remote_atom \". This will open the remote_atom folder as a \"project\". Open the Command Palette ( Cmd+Shift+P or Ctrl+Shift+P ) and type \"Create Sftp\" and choose the option \"Remote Ftp: Create Sftp Config File\". You will notice that a file named .ftpconfig is automatically created in the same folder. Replace the contents of the file with the following, modifying the user and remote parameters: 1 2 3 4 5 6 7 8 9 10 { \"protocol\" : \"sftp\" , \"host\" : \"rce.hmdc.harvard.edu\" , // string - Hostname or IP address of the server. Default: 'localhost' \"port\" : 22 , // integer - Port number of the server. Default: 22 \"user\" : \"<username>\" , // string - Username for authentication. Default: (none) \"promptForPass\" : true , // boolean - Set to true for enable password/passphrase dialog. This will prevent from using cleartext password/passphrase in this config. Default: false \"remote\" : \"/nfs/home/S/shg309/ <replace with your own home folder>\" , // try to use absolute paths starting with / \"connTimeout\" : 10000 , // integer - How long (in milliseconds) to wait for the SSH handshake to complete. Default: 10000 \"keepalive\" : 10000 // integer - How often (in milliseconds) to send SSH-level keepalive packets to the server (in a similar way as OpenSSH's ServerAliveInterval config option). Set to 0 to disable. Default : 10000 } Open the Command Palette and type \"Remote Ftp\", and choose the option Toggle . This will open up a Remote tab on the left hand side. In the Remote tab, click on Connect , and voila! You can now edit files on the cluster as if they were on your own computer! Warning Don't use the remote_atom project unless you're working on the cluster. The files in the folder are uploaded automatically to the cluster when you reconnect. Note Once you're done, remember to Disconnect . Optional: Through the Command Palette, go to \"View Installed Packages\" --> remote_ftp's settings --> change Auto Upload on Save from always to only when connected Configure Hydrogen Through the Command Palette, go to \"View Installed Packages\" --> hydrogen's settings --> change Kernel Gateways to the following (replace <your_token> with the token you set for Jupyter earlier): 1 [{ \"name\" : \"RCE Jupyter\" , \"options\" :{ \"baseUrl\" : \"http://localhost:8889\" , \"token\" : \"<your_token>\" }}]","title":"Setting up Atom"},{"location":"cluster_usage/remote_stata_options/#running-stata-through-hydrogen","text":"Connect to Remote Kernel Open a Stata .do file Through the Command Palette, go to \"Connect to Remote Kernel\". Troubleshooting If you haven't set a token, you might be asked to \"Authenticate Using Token\". To find the authentication token, on an RCE node, type the following: 1 2 3 4 # Activate conda environment conda activate cid # Get Jupyter token jupyter notebook list The token will be of the form: http://localhost:8889/?token= a61elkjziunns1523e70eb18a452cfsdf9812302199b87e Running code Select code you want to run, and hit Cmd+Enter (Mac) or Ctrl+Enter (Windows) To run all code, hit Cmd+Option+Enter (Mac) or Ctrl+Alt+Enter (Windows) Magics For browsing data, you can use the %browse magic: 1 2 3 webuse auto scatter mpg weight %browse 100 mpg Refer to this page for more Jupyter+Stata magics.","title":"Running Stata through Hydrogen"},{"location":"data_management/data_management/","text":"Project Data Management \u00b6 Essentials 1 \u00b6 Backups Cluster data often backed up, but ensure backup frequency is sufficient Solution: external hard drive (local) + cluster backups + CrashPlan (cloud) Above solutions contingent on data agreements / legal restrictions File organization and naming Create a shared system, follow it . Consider date conventions (YYYY-MM-DD), special characters, versioning Documentation (README files) Too much documentation > not enough documentation Document your system aka provide orientation documents Template: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 Title Data Source with link Added by (CID member's name with email) Dates: - Data time period - Date added - Date modified (if required) Description Variable descriptions (incl keys to join with other data) Limitations Other notes (such as licensing, citation, ethical restrictions, legal restrictions, funder requirements, etc.) Data security All researchers working with Human Subjects are required to get IRB ethics training IRB review where required Don't take data off cluster, especially if sensitive Responsibility Assign explicit responsibilities within your project for data management Data Management Checklist \u00b6 Stock-taking: current and future inventory Space requirements, confidentiality and legal requirements Assigned responsibilities for data management Responsibility for enforcement of project data management rules / conventions Storage and backup systems in place Regular backups Off-cluster backups for particularly important data File organization and naming systems in place Data versions - naming and storage conventions Naming, organization and version control for code Access and security guidelines in place Tightly controlled access Understand responsibilities with access Is my data confidential ? Data agreements and legal restrictions Rules, conventions documented Rules and conventions laid out in easily accessible document Handed to new joinees as part of their orientation (both at org and project level) Ethics and privacy concerns addressed Project IRB review IRB ethics certifications Projects involving existing non-public data are usually required to be reviewed by IRB Resources \u00b6 Read the detailed version of the above checklist adapted from MIT Libraries' resources Another good checklist available at page 17 (Appendix A) of ICPSR's booklet Tool available for Data Management Planning: DMPTool . Note that you don't have to \"submit\" the data management plan to a funder through DMPTool unless you're explicitly asked to by the funder. Adapted from MIT Libraries' resources on data management released under a CC-BY license \u21a9","title":"Overview"},{"location":"data_management/data_management/#project-data-management","text":"","title":"Project Data Management"},{"location":"data_management/data_management/#essentials1","text":"Backups Cluster data often backed up, but ensure backup frequency is sufficient Solution: external hard drive (local) + cluster backups + CrashPlan (cloud) Above solutions contingent on data agreements / legal restrictions File organization and naming Create a shared system, follow it . Consider date conventions (YYYY-MM-DD), special characters, versioning Documentation (README files) Too much documentation > not enough documentation Document your system aka provide orientation documents Template: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 Title Data Source with link Added by (CID member's name with email) Dates: - Data time period - Date added - Date modified (if required) Description Variable descriptions (incl keys to join with other data) Limitations Other notes (such as licensing, citation, ethical restrictions, legal restrictions, funder requirements, etc.) Data security All researchers working with Human Subjects are required to get IRB ethics training IRB review where required Don't take data off cluster, especially if sensitive Responsibility Assign explicit responsibilities within your project for data management","title":"Essentials1"},{"location":"data_management/data_management/#data-management-checklist","text":"Stock-taking: current and future inventory Space requirements, confidentiality and legal requirements Assigned responsibilities for data management Responsibility for enforcement of project data management rules / conventions Storage and backup systems in place Regular backups Off-cluster backups for particularly important data File organization and naming systems in place Data versions - naming and storage conventions Naming, organization and version control for code Access and security guidelines in place Tightly controlled access Understand responsibilities with access Is my data confidential ? Data agreements and legal restrictions Rules, conventions documented Rules and conventions laid out in easily accessible document Handed to new joinees as part of their orientation (both at org and project level) Ethics and privacy concerns addressed Project IRB review IRB ethics certifications Projects involving existing non-public data are usually required to be reviewed by IRB","title":"Data Management Checklist"},{"location":"data_management/data_management/#resources","text":"Read the detailed version of the above checklist adapted from MIT Libraries' resources Another good checklist available at page 17 (Appendix A) of ICPSR's booklet Tool available for Data Management Planning: DMPTool . Note that you don't have to \"submit\" the data management plan to a funder through DMPTool unless you're explicitly asked to by the funder. Adapted from MIT Libraries' resources on data management released under a CC-BY license \u21a9","title":"Resources"},{"location":"data_management/folder_structure/","text":"Folder Structure \u00b6 Overall Structure \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 data/ data_1/ raw/ ---- Raw, immutable files file_1 README.md ---- Describes file_1: sources, quirks, codebook processed/ ---- Cleaned, reshaped, filtered files file_1 README.md ---- Describes file_1, the cleaned version. Include codebook if required user_1/ src/ ---- Scripts / do-files are stored here proj/ ---- Notebooks, experimental do-files stored here figs/ tables/ documents/ Example folder structure \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 data/ nightlights/ raw/ luminosity_lksjdf111.csv intermediate/ processed/ luminosity.pq social_security/ raw/ incomes_gibberish.csv intermediate/ processed/ incomes.pq dario/ .git/ .gitignore darios_personal_files.secret src/ preprocessing/ cleaning_master.py cleaning_nightlights.py cleaning_social_security.py commonly_used_functions.py bash_scripts.sh notebooks/ 0-run_cleaning.ipynb 1-modelling.ipynb figs/ tables/ documents/ andres/ .git/ .gitignore src/ preprocessing/ cleaning_master.py cleaning_nightlights.py cleaning_social_security.py commonly_used_functions.py bash_scripts.sh notebooks/ 0-run_cleaning.ipynb 1-modelling.ipynb figs/ tables/ documents/ Notes \u00b6 Data folders: README.md or README.txt files in every raw and processed folders should reference every file in the folders Raw files are immutable - don't touch them once you've downloaded them Intermediate files can be altered freely Processed files can be altered, as long as you first consider the repercussions on subsequent analyses Files are cleaned, reshaped, filtered from raw to intermediate (optional), and finally to processed stages. All analyses have to be based on files in the processed folder ONLY.","title":"Folder structures"},{"location":"data_management/folder_structure/#folder-structure","text":"","title":"Folder Structure"},{"location":"data_management/folder_structure/#overall-structure","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 data/ data_1/ raw/ ---- Raw, immutable files file_1 README.md ---- Describes file_1: sources, quirks, codebook processed/ ---- Cleaned, reshaped, filtered files file_1 README.md ---- Describes file_1, the cleaned version. Include codebook if required user_1/ src/ ---- Scripts / do-files are stored here proj/ ---- Notebooks, experimental do-files stored here figs/ tables/ documents/","title":"Overall Structure"},{"location":"data_management/folder_structure/#example-folder-structure","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 data/ nightlights/ raw/ luminosity_lksjdf111.csv intermediate/ processed/ luminosity.pq social_security/ raw/ incomes_gibberish.csv intermediate/ processed/ incomes.pq dario/ .git/ .gitignore darios_personal_files.secret src/ preprocessing/ cleaning_master.py cleaning_nightlights.py cleaning_social_security.py commonly_used_functions.py bash_scripts.sh notebooks/ 0-run_cleaning.ipynb 1-modelling.ipynb figs/ tables/ documents/ andres/ .git/ .gitignore src/ preprocessing/ cleaning_master.py cleaning_nightlights.py cleaning_social_security.py commonly_used_functions.py bash_scripts.sh notebooks/ 0-run_cleaning.ipynb 1-modelling.ipynb figs/ tables/ documents/","title":"Example folder structure"},{"location":"data_management/folder_structure/#notes","text":"Data folders: README.md or README.txt files in every raw and processed folders should reference every file in the folders Raw files are immutable - don't touch them once you've downloaded them Intermediate files can be altered freely Processed files can be altered, as long as you first consider the repercussions on subsequent analyses Files are cleaned, reshaped, filtered from raw to intermediate (optional), and finally to processed stages. All analyses have to be based on files in the processed folder ONLY.","title":"Notes"}]}